Let’s assume we have following cluster configuration:
Number Of Node : 10
CPU cores per node: 16
RAM per node : 64 gb
-------------------------------------------------
Each executor can hold a minimum of 1 core and a maximum of 16 (i.e., a CPU core for each node).
If we consider the minimum value, i.e., 1 core per executor.
In that case, we will have :

 Number of cores per executor: 1
Number of executors: 16.
Executor Memory : 64 GB/16 = 4 GB
The number of cores per executor decides the parallel task, so in this case, we can not execute more than one task at a time.
This process is also called "tiny executor."
------------------------------------------------
2nd Process: 
Let's assign all 16 cores to one executor.
In that case, we will have :
1. Number of executors: 1
2. CPU cores per executors: 16
3. Executor Memory : 64 GB/1 = 64 GB

Here we will have 16 parallel tasks. If we execute more than five parallel processes or have more than five cores per executor, then the process might get slow in a spark.
This is also not a good cluster configuration. This process is also called "FAT executor."
So the above tiny and fat executor is not a good cluster configuration.
---------------------------------------------------------------
Let’s try to configure an optimised cluster.
Resources
1. Total Node Count: 10
2. Cores Per Node : 16.
3. RAM Per Node : 64 GB
So, from the above resources, we need to give 1 core and 1 GB of RAM for other OS activities.
 
So , now we will have
1. Total Node Count: 10
2. Cores Per Node : 16-1 = 15.
3. RAM per node: 64 GB - 1 = 63 GB
As per the study, 5 cores per executor (5 parallel tasks) is the best and preferred choice.
 
So here we can have :
No Of executors Per node = total core in one node / Number of Cores per Executor
The number of executors per node is = 15/5.
No Of executors Per node = 3

Memory Per Executor = total Memory /No of Executor
Memory Per Executor = 63 Gb/3
Memory Per Executor = 21 Gb
 
1 Node with 3 Executors----5 Cores for each Executor----> 21 GB of RAM per Executor.
Out Of this 21GB RAM , some of Will go as part of overhead memory(off heap).
overhead memory= max(384 MB,7% Of Executor Memory)
i.e max(384 MB, 7% Of 21 GB)~1.5 GB
So the remaining memory will be 21–1.5 ~19 GB
So the calculation will be
Number Of Nodes : 10

Total Executor In Cluster : total_No_of_Nodes * Executor_Per_Node

Total Executor In Cluster : 10 * 3
Total Executor In Cluster : 30 
So there will be 30 executors, with each executor holding 5 CPU cores and 19 GB of memory.
One of these 30 executors will be assigned to the Yarn Applications Manager.
As a result, our final cluster configuration will be :
Number Of Nodes : 10 nodes. 
Total Number of Executors : 30-1 = 29 
Core Per Executor : 5
RAM Per Executor :19 GB